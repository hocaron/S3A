# 11장 카프카 커넥트
- **카프카 커넥트**는 외부 시스템과 카프카를 손쉽게 연결하기 위한 프레임워크이다.
- 제공하는 REST API를 통해 빠르고 간단하게 커넥트의 설정을 조정하며 상황에 맞게 유연하게 대응할 수 있다.
- 주요 장점은 다음과 같다.
  - 👍 데이터 중심 파이프라인
  - 👍 유연성과 확장성
  - 👍 재사용성과 기능 확장
  - 👍 장애 및 복구

<br/>

## 11.1 카프카 커넥트의 핵심 개념

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/3340c4ff-0a46-4788-b740-2ac6b57dfa0a"/>

🔼 카프카 커넥트 구성도
- 카프카를 기준으로 들어오고 나가는 양방향에 커넥트가 존재한다.
  - 소스 방향에 있는 커넥트를 **소스 커넥트**라고 한다.
  - 싱크 방향에 있는 커넥트를 **싱크 커넥트**라고 한다.
 
<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/cf1cb4fb-1ed3-4e5e-a02e-bbd1b856765d"/>

🔼 카프카 커넥트 상세 구성도
- 총 3대의 워커(인스턴스)를 실행한 분산 모드 소스 커넥트를 나타낸 것이다.
- **워커**는 카프카 커넥트 프로세스가 실행되는 서버 또는 인스턴스 등을 의미하며, 커넥터나 태스크들이 워커에서 실행된다.
- 👍 분산 모드는 특정 워커에 장애가 발생하더라도 해당 워커에서 동작 중인 커넥터나 태스크들이 다른 워커로 이동해 **연속으로 동작**할 수 있다.
- **커넥터**는 직접 데이터를 복사하지 않고, 데이터를 어디에서 어디로 복사해야 하는지의 작업을 정의하고 관리하는 역할을 한다.
- **태스크**는 커넥터가 정의한 작업을 직접 수행하는 역할을 한다.

<br/>

## 11.2 카프카 커넥트의 내부 동작

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/28416ad6-afd8-4850-891c-1610ed72f676"/>

🔼 소스 커넥터 내부 동작 구성도
- 각 태스크들은 메시지들을 이동시키는데, 이때 커넥트는 파티셔닝 개념을 적용해 데이터들을 하위 집합으로 나눈다.
- 커넥터에서 나뉜 파티션들에는 오프셋과 같이 순차적으로 레코드들이 정렬된다.
- (1) 스트림 영역으로 표시된 부분이 데이터가 파티셔닝된 것을 나타낸다.
- (2) 최대 태스크 수는 2로 정의되어 있다.
- 결과적으로 태스크1은 토픽A와 토픽B에 데이터를 전송하고, 태스크2는 토픽B와 토픽C에 데이터를 전송한다.

<br/>

## 11.3 단독 모드 카프카 커넥트

```
$ cd kafka2/
$ cd chapter2/ansible_playbook
$ ansible-playbook -i hosts kafka.yml
```
🔼 새로운 카프카 클러스터 생성
- 카프카 커넥트는 카프카 설치 파일 안에 패키징되어 있다. (별도 설치 필요X)

<br/>

### 11.3.1 파일 소스 커넥터 실행

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/707cd603-fa24-4467-9db1-1eaa3f33bee4"/>

🔼 connect-test 토픽으로 데이터를 주고받는 파일 커넥터의 구조
- 로컬 디렉토리에 test.txt라는 파일을 생성한 후 **파일 소스 커넥터를 실행**하면, 파일 소스 커넥터는 로컬의 test.txt 파일 내용을 읽은 다음 카프카의 connect-test라는 **토픽으로 메시지를 전송**한다.
- **파일 싱크 커넥터**는 connect-test 토픽에서 **메시지를 읽은 뒤** 해당 내용을 로컬의 test.sink.txt **파일로 저장**한다.

<br/>

```
$ echo "hello-1" > test.txt
$ echo "hello-2" >> test.txt
$ echo "hello-3" >> test.txt
```
🔼 (서버 접속) text.txt 파일 생성
- test.txt 파일에는 총 3개의 메시지가 저장되어 있다.

<br/>

```
name=local-file-source # 커넥터에서 식별하는 이름
connector.class=FileStreamSource # 커넥터에서 사용하는 클래스
tasks.max=1 # 실제 작업을 처리하는 태스크의 최대 수
file=/home/ec2-user/test.txt # 파일 소스 커넥터가 읽을 파일
topic=connect-test # 파일 소스 커넥터가 읽은 내용을 전송할 토픽
```
🔼 connect-file-source.properties 예제
- 설정 파일 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-file-source.properties`)
- 소스 파일 커넥터에서 test.txt 파일을 인지하도록 한다.

<br/>

```
bootstrap.servers=localhost:9092 # 브로커 주소

# 카프카로 데이터를 보내거나 가져올 때 사용하는 포맷 지정 (key, value)
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.json.JsonConverter

# 스키마가 포함된 구조 사용 여부
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.file.filename=/tmp/connect.offsets # 재처리 등을 목적으로 오프셋을 파일로 저장하는 경로
offset.flush.interval.ms=10000 # 오프셋 플러시 주기 (단위 ms)
```
🔼 카프카 커넥트 단독 모드 설정 파일(connect-standalone.properties)
- 설정 파일 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-standalone.properties`)

<br/>

```
$ sudo /usr/local/kafka/bin/connect-standalone.sh -daemon /usr/local/kafka/config/connect-standalone.properties /usr/local/kafka/config/connect-file-source.properties
```
🔼 connect-standalone.sh 파일 실행
- 카프카 커넥트를 단독 모드로 실행한다.
- 카프카 커넥트가 잘 실행됐는지는 REST API를 이용해 현재 상태를 확인할 수 있다.
  ```
  $ curl http://localhost:8083/connectors/local-file-source | python -m json.tool
  ```

<br/>

### 11.3.2 파일 싱크 커넥터 실행

```
$ curl --header "Content-Type: application/json" --header
"Accept: application/json" --request PUT --data '{
"name": "local-file-sink", # 커넥터에서 식별하는 이름
"connector.class": "FileStreamSink", # 커넥터에서 사용하는 클래스
"tasks.max": "1", # 실제 작업을 처리하는 태스크의 최대 수
"file": "/home/ec2-user/test.sink.txt", # 파일 싱크 커넥터가 가져온 메시지를 저장하는 경로
"topics": "connect-test" # 파일 싱크 커넥터가 메시지를 가져오는 토픽
}' http://localhost:8083/connectors/local-file-sink/config
```
🔼 파일 싱크 커넥터 실행
- REST API를 이용해 실행할 수도 있다.
- 잘 실행되었는지도 REST API를 이용해 확인할 수 있다.
  ```
  $ curl http://localhost:8083/connectors/local-file-sink | python -m json.tool
  ```
- `test.sink.txt` 파일을 열어보면 가져온 메시지를 확인할 수 있다.

<br/>

```
$ sudo pkill -f connect
```
🔼 커넥트 종료

<br/>

## 11.4 분산 모드 카프카 커넥트
- 운영 환경에서는 분산 모드(클러스터)로 사용하는 것이 안정적인 운영에 도움을 준다.
- 분산 모드는 **메타 정보의 저장소**로 카프카 내부 토픽을 이용한다. (워커 장애 시에도 유연하게 대응 가능)
- 카프카 커넥트에서 사용하는 토픽들은 커넥트 운영에서 중요한 정보가 저장되어 있으므로, 리플리케이션 팩터 수는 반드시 3으로 설정해야 한다.
- 카프카 커넥트는 안전한 메타 저장소를 바탕으로 확장성, 장애 허용, 자동 리밸런싱 등 운영에 필요한 필수 기능을 제공한다.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/ddcc7964-a34f-4a39-8a77-1df267446962"/>

🔼 커넥트 확장과 자동 리밸런싱 동작
- 관리자가 긴급으로 카프카 커넥트에 워커4를 추가하면 커넥트는 즉시 확장된다.
- 내부적으로 자동 리밸런싱 동작에 의해 워커2에 있던 커넥터B가 워커4로 이동한다.
- 자동 리밸런싱은 워커들 안에서 태스크와 커넥터가 최대한 균등하게 배치될 수 있게 한다.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/04955882-342e-4834-a9f7-675fad3799d5"/>

🔼 장애가 발생한 워커3의 장애 허용 동작
- 장애가 발생한 워커3이 종료되면서 워커3에서 동작 중이던 태스크B1은 워커2로 이동해서 다시 본래의 작업을 처리한다.
- 카프카 커넥트를 분산 모드로 실행하려면 최소 2대 이상의 워커로 구성해야 한다. (for 자동 리밸런싱 동작, 장애 대응)

<br/>

```
bootstrap.servers=peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092
group.id=peter-connect-cluster # 분산 모드의 그룹 아이디
key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

# 커넥터들의 오프셋 추적을 위해 저장하는 카프카 내부 토픽
offset.storage.topic=connect-offsets
offset.storage.replication.factor=3
offset.storage.partitions=25

# 커넥터들의 설정을 저장하는 카프카 내부 토픽
config.storage.topic=connect-configs
config.storage.replication=3
config.storage.partitions=1

# 커넥터들의 상태를 저장하는 카프카 내부 토픽
status.storage.topic=connect-status
status.storage.replication=3
status.storage.partitions=5

offset.flush.interval.ms=10000
```
🔼 카프카 커넥트 분산 모드 설정 파일(connect-distributed.properties)
- 설정 파일의 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-distributed.properties`)

<br/>

```
$ sudo systemctl start kafka-connect
```
🔼 커넥트 실행

<br/>

```
$ sudo systemctl status kafka-connect
```
- 커넥트 프로세스가 잘 실행됐는지 확인할 수 있다.
- 출력 결과에서 `Active: active (running)`이 확인되면 정상적으로 실행된 것이다.

<br/>

## 11.5 커넥터 기반의 미러 메이커 2.0
