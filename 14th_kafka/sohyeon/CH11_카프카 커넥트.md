# 11장 카프카 커넥트
- **카프카 커넥트**는 외부 시스템과 카프카를 손쉽게 연결하기 위한 프레임워크이다.
- 제공하는 REST API를 통해 빠르고 간단하게 커넥트의 설정을 조정하며 상황에 맞게 유연하게 대응할 수 있다.
- 주요 장점은 다음과 같다.
  - 👍 데이터 중심 파이프라인
  - 👍 유연성과 확장성
  - 👍 재사용성과 기능 확장
  - 👍 장애 및 복구

<br/>

## 11.1 카프카 커넥트의 핵심 개념

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/3340c4ff-0a46-4788-b740-2ac6b57dfa0a"/>

🔼 카프카 커넥트 구성도
- 카프카를 기준으로 들어오고 나가는 양방향에 커넥트가 존재한다.
  - 소스 방향에 있는 커넥트를 **소스 커넥트**라고 한다.
  - 싱크 방향에 있는 커넥트를 **싱크 커넥트**라고 한다.
 
<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/cf1cb4fb-1ed3-4e5e-a02e-bbd1b856765d"/>

🔼 카프카 커넥트 상세 구성도
- 총 3대의 워커(인스턴스)를 실행한 분산 모드 소스 커넥트를 나타낸 것이다.
- **워커**는 카프카 커넥트 프로세스가 실행되는 서버 또는 인스턴스 등을 의미하며, 커넥터나 태스크들이 워커에서 실행된다.
- 👍 분산 모드는 특정 워커에 장애가 발생하더라도 해당 워커에서 동작 중인 커넥터나 태스크들이 다른 워커로 이동해 **연속으로 동작**할 수 있다.
- **커넥터**는 직접 데이터를 복사하지 않고, 데이터를 어디에서 어디로 복사해야 하는지의 작업을 정의하고 관리하는 역할을 한다.
- **태스크**는 커넥터가 정의한 작업을 직접 수행하는 역할을 한다.

<br/>

## 11.2 카프카 커넥트의 내부 동작

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/28416ad6-afd8-4850-891c-1610ed72f676"/>

🔼 소스 커넥터 내부 동작 구성도
- 각 태스크들은 메시지들을 이동시키는데, 이때 커넥트는 파티셔닝 개념을 적용해 데이터들을 하위 집합으로 나눈다.
- 커넥터에서 나뉜 파티션들에는 오프셋과 같이 순차적으로 레코드들이 정렬된다.
- (1) 스트림 영역으로 표시된 부분이 데이터가 파티셔닝된 것을 나타낸다.
- (2) 최대 태스크 수는 2로 정의되어 있다.
- 결과적으로 태스크1은 토픽A와 토픽B에 데이터를 전송하고, 태스크2는 토픽B와 토픽C에 데이터를 전송한다.

<br/>

## 11.3 단독 모드 카프카 커넥트

```
$ cd kafka2/
$ cd chapter2/ansible_playbook
$ ansible-playbook -i hosts kafka.yml
```
🔼 새로운 카프카 클러스터 생성
- 카프카 커넥트는 카프카 설치 파일 안에 패키징되어 있다. (별도 설치 필요X)

<br/>

### 11.3.1 파일 소스 커넥터 실행

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/707cd603-fa24-4467-9db1-1eaa3f33bee4"/>

🔼 connect-test 토픽으로 데이터를 주고받는 파일 커넥터의 구조
- 로컬 디렉토리에 test.txt라는 파일을 생성한 후 **파일 소스 커넥터를 실행**하면, 파일 소스 커넥터는 로컬의 test.txt 파일 내용을 읽은 다음 카프카의 connect-test라는 **토픽으로 메시지를 전송**한다.
- **파일 싱크 커넥터**는 connect-test 토픽에서 **메시지를 읽은 뒤** 해당 내용을 로컬의 test.sink.txt **파일로 저장**한다.

<br/>

```
$ echo "hello-1" > test.txt
$ echo "hello-2" >> test.txt
$ echo "hello-3" >> test.txt
```
🔼 (서버 접속) text.txt 파일 생성
- test.txt 파일에는 총 3개의 메시지가 저장되어 있다.

<br/>

```
name=local-file-source # 커넥터에서 식별하는 이름
connector.class=FileStreamSource # 커넥터에서 사용하는 클래스
tasks.max=1 # 실제 작업을 처리하는 태스크의 최대 수
file=/home/ec2-user/test.txt # 파일 소스 커넥터가 읽을 파일
topic=connect-test # 파일 소스 커넥터가 읽은 내용을 전송할 토픽
```
🔼 connect-file-source.properties 예제
- 설정 파일 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-file-source.properties`)
- 소스 파일 커넥터에서 test.txt 파일을 인지하도록 한다.

<br/>

```
bootstrap.servers=localhost:9092 # 브로커 주소

# 카프카로 데이터를 보내거나 가져올 때 사용하는 포맷 지정 (key, value)
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.json.JsonConverter

# 스키마가 포함된 구조 사용 여부
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.file.filename=/tmp/connect.offsets # 재처리 등을 목적으로 오프셋을 파일로 저장하는 경로
offset.flush.interval.ms=10000 # 오프셋 플러시 주기 (단위 ms)
```
🔼 카프카 커넥트 단독 모드 설정 파일(connect-standalone.properties)
- 설정 파일 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-standalone.properties`)

<br/>

```
$ sudo /usr/local/kafka/bin/connect-standalone.sh -daemon /usr/local/kafka/config/connect-standalone.properties /usr/local/kafka/config/connect-file-source.properties
```
🔼 connect-standalone.sh 파일 실행
- 카프카 커넥트를 단독 모드로 실행한다.
- 카프카 커넥트가 잘 실행됐는지는 REST API를 이용해 현재 상태를 확인할 수 있다.
  ```
  $ curl http://localhost:8083/connectors/local-file-source | python -m json.tool
  ```

<br/>

### 11.3.2 파일 싱크 커넥터 실행

```
$ curl --header "Content-Type: application/json" --header
"Accept: application/json" --request PUT --data '{
"name": "local-file-sink", # 커넥터에서 식별하는 이름
"connector.class": "FileStreamSink", # 커넥터에서 사용하는 클래스
"tasks.max": "1", # 실제 작업을 처리하는 태스크의 최대 수
"file": "/home/ec2-user/test.sink.txt", # 파일 싱크 커넥터가 가져온 메시지를 저장하는 경로
"topics": "connect-test" # 파일 싱크 커넥터가 메시지를 가져오는 토픽
}' http://localhost:8083/connectors/local-file-sink/config
```
🔼 파일 싱크 커넥터 실행
- REST API를 이용해 실행할 수도 있다.
- 잘 실행되었는지도 REST API를 이용해 확인할 수 있다.
  ```
  $ curl http://localhost:8083/connectors/local-file-sink | python -m json.tool
  ```
- `test.sink.txt` 파일을 열어보면 가져온 메시지를 확인할 수 있다.

<br/>

```
$ sudo pkill -f connect
```
🔼 커넥트 종료

<br/>

## 11.4 분산 모드 카프카 커넥트
- 운영 환경에서는 분산 모드(클러스터)로 사용하는 것이 안정적인 운영에 도움을 준다.
- 분산 모드는 **메타 정보의 저장소**로 카프카 내부 토픽을 이용한다. (워커 장애 시에도 유연하게 대응 가능)
- 카프카 커넥트에서 사용하는 토픽들은 커넥트 운영에서 중요한 정보가 저장되어 있으므로, 리플리케이션 팩터 수는 반드시 3으로 설정해야 한다.
- 카프카 커넥트는 안전한 메타 저장소를 바탕으로 확장성, 장애 허용, 자동 리밸런싱 등 운영에 필요한 필수 기능을 제공한다.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/ddcc7964-a34f-4a39-8a77-1df267446962"/>

🔼 커넥트 확장과 자동 리밸런싱 동작
- 관리자가 긴급으로 카프카 커넥트에 워커4를 추가하면 커넥트는 즉시 확장된다.
- 내부적으로 자동 리밸런싱 동작에 의해 워커2에 있던 커넥터B가 워커4로 이동한다.
- 자동 리밸런싱은 워커들 안에서 태스크와 커넥터가 최대한 균등하게 배치될 수 있게 한다.

<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/04955882-342e-4834-a9f7-675fad3799d5"/>

🔼 장애가 발생한 워커3의 장애 허용 동작
- 장애가 발생한 워커3이 종료되면서 워커3에서 동작 중이던 태스크B1은 워커2로 이동해서 다시 본래의 작업을 처리한다.
- 카프카 커넥트를 분산 모드로 실행하려면 최소 2대 이상의 워커로 구성해야 한다. (for 자동 리밸런싱 동작, 장애 대응)

<br/>

```
bootstrap.servers=peter-kafka01.foo.bar:9092,peter-kafka02.foo.bar:9092,peter-kafka03.foo.bar:9092
group.id=peter-connect-cluster # 분산 모드의 그룹 아이디
key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

# 커넥터들의 오프셋 추적을 위해 저장하는 카프카 내부 토픽
offset.storage.topic=connect-offsets
offset.storage.replication.factor=3
offset.storage.partitions=25

# 커넥터들의 설정을 저장하는 카프카 내부 토픽
config.storage.topic=connect-configs
config.storage.replication=3
config.storage.partitions=1

# 커넥터들의 상태를 저장하는 카프카 내부 토픽
status.storage.topic=connect-status
status.storage.replication=3
status.storage.partitions=5

offset.flush.interval.ms=10000
```
🔼 카프카 커넥트 분산 모드 설정 파일(connect-distributed.properties)
- 설정 파일의 내용을 수정한다. (위치: `/usr/local/kafka/config/connect-distributed.properties`)

<br/>

```
$ sudo systemctl start kafka-connect
```
🔼 커넥트 실행

<br/>

```
$ sudo systemctl status kafka-connect
```
- 커넥트 프로세스가 잘 실행됐는지 확인할 수 있다.
- 출력 결과에서 `Active: active (running)`이 확인되면 정상적으로 실행된 것이다.

<br/>

## 11.5 커넥터 기반의 미러 메이커 2.0
- 카프카와 카프카 간 리플리케이션을 하기 위한 도구 중 하나가 **미러 메이커**이고, 아파치 카프카에서는 미러 메이커를 기본 도구로 제공한다.
- 👍 미러 메이커 2.0은 카프카 커넥트 프레임워크 기반으로 간단한 설정만으로도 손쉬운 확장이 가능하다.

<br/>

> **원격 토픽과 에일리어스 가능**

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/67733dde-be09-45c8-8a2a-257aecab8be7"/>

🔼 미러 메이커 2.0을 이용한 액티브/액티브 리플리케이션
- 미러 메이커 2.0을 이용해 A 카프카 클러스터와 B 카프카 클러스터가 양방향 리플리케이션을 수행하는 동작이다.
- 에일리어스(alias)를 추가해 서로의 토픽명을 구분할 수 있게 한다. (양방향 미러링 가능)
  - A 카프카 클러스터의 topic1.part0 토픽이 B 카프카 클러스터의 A.topic1.part0 토픽으로 미러링되고 있다.
  - B 카프카 클러스터의 topic1.part0 토픽은 A 카프카 클러스터의 B.topic1.part0 토픽으로 미러링되고 있다.
 
<br/>

> **카프카 클러스터 통합**

- 다중 클러스터로부터 미러링된 토픽들을 다운스트림 컨슈머가 통합할 수 있다.
- 원본 토픽의 내용과 정확하게 일치하며, 관리자는 데이터를 처리함에 있어 원하는 형태로 토픽을 컨슘할 수 있다.

<br/>

> **무한 루프 방지**

- 관리자가 동시에 2개의 클러스터를 서로 리플리케이션할 수 있도록 구성할 수 있다.
- 토픽의 이름 앞에 에일리어스를 추가함으로써 접두어가 추가된 토픽은 리플리케이션하지 않으므로 무한 루프를 방지할 수 있다.

<br/>

> ***토픽 설정 동기화**

- 소스 토픽을 모니터링하고 토픽의 설정 변경사항을 원격의 대상 토픽으로 전파한다.
- 👍 원격 토픽의 설정을 실수로 누락해도 자동으로 적용된다.

<br/>

> **안전한 저장소로 내부 토픽 활용**

- 내부적으로 미리 메이커가 잘 동작하는지 정상상태 점검을 하며, 주기적으로 미러링 관련 토픽, 파티션, 오프셋 정보 등을 저장하기 위해 가장 안전한 저장소인 카프카의 내부 토픽을 사용한다.
- 내부 토픽에는 정상상태 점검을 위한 하트비트, 컨슈머 그룹의 오프셋 정보를 위한 체크포인트, 각 토픽의 파티션 리플리케이션 체크를 위한 오프셋 싱크 등이 저장된다.

<br/>

> **카프카 커넥트 지원**

- 미러 메이커 2.0을 실행하는 방법은 다음과 같다.
  1. 전용 미러 메이커 클러스터
  2. **분산 커넥트 클러스터에서 미러 메이커 커넥터 이용**
  3. 독립형인 커넥트 워커
  4. 레거시 방식인 스크립트 사용
 
<br/>

<img alt="image" width="500" src="https://github.com/mash-up-kr/S3A/assets/55437339/ad51e8cb-ac47-46f6-9704-4f250c3ae827"/>

🔼 미러 메이커 2.0 구성도
- 2개의 카프카 클러스터에 에일리어스를 이용해 각각 소스 카프카는 src로, 타깃 카프카는 dst로 지정한다.

<br/>

```
$ /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-zk01.foo.bar:9092 --create --topic peter-mirror01 --partitions 1 --replication-factor 3
$ /usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server peter-zk01.foo.bar:9092 --topic peter-mirror01
> mirror-maker-2.0
```
- 토픽을 생성하고, 메시지를 전송한다.

<br/>

```
$ curl --header "Content-Type: application/json" --header
"Accept: application/json" --request PUT --data '{
"name": "peter-mirrormaker2",
"connector.class": "org.apache.kafka.connect.mirror.MirrorSourceConnector", # 커넥터에서 사용하는 클래스
"tasks.max": "1",

# 소스 클러스터와 타깃 클러스터의 에일리어스 지정
"source.cluster.alias": "src",
"target.cluster.alias": "dst",

# 소스 클러스터와 타깃 클러스터의 부트스트랩 서버 리스트 설정
"source.cluster.bootstrap.servers": "peter-zk01.foo.bar:9092,peter-zk02.foo.bar:9092,peter-zk03.foo.bar:9092",
"target.cluster.bootstrap.servers": "peter-zk01.foo.bar:9092,peter-zk02.foo.bar:9092,peter-zk03.foo.bar:9092",

"replication.factor": "3", # 타깃 클러스터의 토픽을 생성할 때 리플리케이션 팩터 수 지정
"topics": ".*",
}', http://peter-kafka03.foo.bar:8083/connectors/peter-mirrormaker2/config
```
🔼 미러 메이커 2.0 실행
- 실행 및 동작 여부는 REST API를 이용해 확인할 수 있다.

<br/>

```
$ /usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 --list
```
- 미머링된 토픽 리스트를 조회한다.

<br/>

```
$ /usr/local/kafka/bin/kafka-console-consumer.sh --bootstrap-server peter-kafka01.foo.bar:9092 --topic src.peter-mirror01 --from-beginning
```
- 메시지도 정확하게 미러링 됐는지 콘솔 컨슈머를 이용해 확인한다.

<br/>

```
$ sudo systemctl stop kafka-connect
```
- 장애 대응을 확인해보기 위해서 카프카 커넥트를 종료한다.
- REST API를 2번 실행해보면, 상태가 UNASSIGNED에서 RUNNING으로 다시 변경되는 것을 확인할 수 있다. (자동 장애 복구)
- 분산 모드로 카프카 커넥트를 구성하면 장애 시에도 유연하게 대응할 수 있는 안정성을 확보할 수 있다. (운영 환경에 good)
