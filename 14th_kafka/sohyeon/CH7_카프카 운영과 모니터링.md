# 7장 카프카 운영과 모니터링
- 카프카 클러스터를 구축할 때의 고려사항과 카프카 클러스터를 구축한 후 안정적인 운영을 위한 모니터링 방법을 살펴본다.
- 그라파나(Grafana)와 프로메테우스(Prometheus)를 기반으로 카프카와 하드웨어 리소스를 모니터링한다.

<br/>

## 7.1 안정적인 운영을 위한 주키퍼와 카프카 구성
- 카프카 클러스터 운영을 위해 고려할 사항들을 알아본다.

<br/>

### 7.1.1 주키퍼 구성
- 주키퍼는 파티션과 브로커의 메타데이터를 저장하고 컨트롤러 서버를 선출하는 동작을 수행한다.

<br/>

> **주키퍼 서버 수량**

- 주키퍼는 기본적으로 쿼럼(과반수) 구성을 기반으로 동작하므로 반드시 **홀수로 구성**해야 한다.
- 최소 서버 수량은 3으로, 과반수인 2를 충족할 수 있는 최대 1대까지의 주키퍼 장애를 허용한다. (5일 경우 최대 2대까지의 장애 허용)
- 카프카의 사용량이 높지 않으며 카프카가 매우 중요한 클러스터가 아니라면 주키퍼는 3대로 구성하는 것이 적합하다.
- 핵심 중앙 데이터 파이프라인으로 카프카를 이용 중이거나 카프카의 사용량도 높다면 주키퍼는 5대로 구성하여 안정성을 높이는 것이 권장된다.

<br/>

> **주키퍼 하드웨어**

- **물리적인 메모리 크기는 4~8GB**, **디스크는 240G 또는 480SSD** 사용이 권장된다. (높은 하드웨어 리소스를 요구하지 않음)
- 주키퍼 서버에 과도한 물리 메모리를 장착하는 것은 오히려 메모리를 낭비하는 일이 될 수 있다.
- 트랜잭션이나 스냅샷 로그들은 로컬 디스크에 저장하는데, 쓰기 성능이 좋은 SSD 디스크를 추천한다.
- 네트워크 카드는 1G 이더넷 카드로 구성하면 된다. (주키퍼와 카프카 간 메타데이터 정도만 주고받으므로 네트워크 사용량이 높지 않음)

<br/>

> **주키퍼 배치**

- 주키퍼를 각기 다른 랙에 분산 배치하는 방안을 권장하며, 이와 동시에 전원 이중화나 스위치 이중화 등도 고려해야 한다.
- AWS에서도 분산 배치를 위해 가용 영역을 운영하므로 가능한 한 2개 또는 3개의 가용 영역에 분산해 구성하는 것을 추천한다.

<br/>

### 7.1.2 카프카 구성
- 안정적인 카프카 클러스터를 구성하기 위한 고려사항을 살펴본다.

<br/>

> **카프카 서버 수량**

- 쿼럼 방식의 구성이 필요하지 않으므로 카프카 클러스터의 수가 반드시 홀수일 필요는 없다.
- 카프카의 최소 구성에서 3대가 가장 적당하다. (안정적인 리플리케이션 팩터 수는 3)

<br/>

> **카프카 하드웨어**

- CPU 사용률이 높은 편이므로, 코어 수가 많은 CPU로 구성할 것이 권장된다.
- 어느 정도 메모리 여유가 있어야 성능에 도움이 된다.
  - 최소 32GB 이상 구성하는 것을 추천한다.
  - 힙 크기를 제외한 나머지 물리 메모리는 모두 페이지 캐시로 사용해서 빠른 처리를 돕는다.
 
- 저성능의 SATA 디스크를 사용해도 카프카는 높은 성능을 보장할 수 있다.
  - 로그 마지막에 순차적으로 쓰는 방식으로 로그를 기록한다.
  - 병렬 처리를 위해 약 10개 정도의 디스크를 장착한다.
  - 토픽의 보관 주기를 충분하게 설정하려면 4TB 용량 이상의 디스크로 선정하는 것을 추천한다.
 
- 네트워크 카드는 10G 이더넷 카드로 구성하는 것을 추천한다.
  - 브로커 한 대당 네트워크 사용량 비율이 50%가 넘지 않도록 최대한 토픽을 분산해 운영해야 한다.
  - 디스크의 장애 복구 또는 신규 브로커 추가로 인해 카프카 클러스터 간 대량의 데이터 이동이 발생할 수 있으므로 네트워크 대역폭은 충분히 확보되어야 한다.
 
<br/>

> **카프카 배치**

- 여러 랙에 분산시켜 카프카 서버를 배치하는 방식을 추천한다.
- AWS에서 구성할 경우 멀티 가용 영역으로 구성하는 것을 추천한다.

<br/>

## 7.2 모니터링 시스템 구성
- 오픈소스 기반의 카프카 모니터링 시스템을 직접 구성해보며 카프카를 모니터링하는 방법을 살펴본다.
- 대표적으로 애플리케이션 로그 분석과 JMX를 이용해 브로커들의 메트릭 정보를 확인할 수 있다.

<br/>

### 7.2.1 애플리케이션으로서 카프카의 로그 관리와 분석
- 카프카는 애플리케이션 로그 관리를 위해 log4j를 이용한다.
- log4j는 애플리케이션의 레벨별로 로깅이 가능하며, 관리자는 로그의 레벨을 보고 상황의 심각성 등을 유추할 수 있다.
  |로그 레벨|설명|
  |---|---|
  |TRACE|DEBUG보다 상세한 로그를 기록함|
  |DEBUG|내부 애플리케이션 상황에 대한 로그를 기록함|
  |INFO|로그 레벨의 기본값이며, 일반적인 정보 수준의 로그를 기록함|
  |WARN|INFO 로그 레벨보다 높은 개념으로, 경고 수준의 로그를 기록함|
  |ERROR|경고 수준을 넘어 런타임 에러나 예상하지 못한 에러 로그를 기록함|
  |FATAL|로그 레벨 중 최종 단계이며, 심각한 오류로 인한 애플리케이션 중지 등의 로그를 기록함|

  🔼 log4j 로그 레벨

<br/>

> **실습**

```
$ cat /usr/local/kafka/config/log4j.properties
```
🔼 (브로커 서버 접속 중) log4j 파일 내용 확인

<br/>

```
...

log4j.logger.kafka=INFO
log4j.logger.org.apache.kafka=INFO

...
```
🔼 출력 결과
- 로그 레벨이 INFO로 적용됐음을 알 수 있다.
- 로그 레벨을 변경하고 싶다면 INFO 대신 다른 레벨 값으로 수정하면 된다.

<br/>

```
$ sudo systemctl restart kafka-server
$ cat /usr/local/kafka/logs/server.log
```
🔼 브로커 재시작 후 server.log 로그 파일 확인
- 로그 파일을 확인해보면 DEBUG 레벨로 기록된 로그를 확인할 수 있다.
- 로그 레벨이 낮을수록 로그의 양이 증가하므로 여유 디스크 공간이 충분한지 확인해야 한다.

<br/>

|로그 파일 이름|설명|
|server.log|브로커 설정 정보와 정보성 로그 등을 기록함|
|state-change.log|컨트롤러로부터 받은 정보를 기록함|
|kafka-request.log|클라이언트로부터 받은 정보를 기록함|
|log-cleaner.log|로그 컴팩션 동작들을 기록함|
|controller.log|컨트롤러 관련 정보를 기록함|
|kafka-authorizer.log|인증과 관련된 정보를 기록함|

🔼 카프카 애플리케이션의 로그 파일 종류와 역할

<br/>

### 7.2.2 JMX를 이용한 카프카 메트릭 모니터링
