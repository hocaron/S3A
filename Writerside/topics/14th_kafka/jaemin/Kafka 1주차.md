# Kafka 1주차

# 1장 카프카 개요

카프카는 링크드인 내부에서 발생하고 있는 이슈들을 해결하기 위해 만들어졌다. 링크드인에서 겪던 고질적인 문제점들, 예를 들어 데이터 파이프라인 확장의 어려움, 이기종 간의 호환성, 고성능 기반의 실시간 데이터 처리의 어려움 등의 문제를 해결하기 위해 2010년 개발된 카프카는 일 년 뒤인 2011년 아파치 오픈소스로 세상에 공개되었다.

링크드인 자사에서 직접 개발한 카프카를 첫 도입하자 링크드인 서비스를 사용하는 고객의 직장이 변경되면 해당 변경 내용이 링크드인을 사용하는 지인들에게 즉시 업데이트되고 링크드인 내부 서비스에도 즉시 반영돼 추천 로직을 거쳐 실시간으로 직장을 추천해주는게 가능해져 실시간 스트리밍 플랫폼이 필요한 곳에서 대부분 카프카를 필수 요소로 채택해 사용하고 있다.

1장에서는 카프카를 도입한 국내외 여러 기업들의 구체적 사례를 통해 카프카가 주는 이점이 무엇이며 기업들이 왜 카프카를 도입하려 하는지 그 이유를 살펴보자.

## 1.1 잘란도와 트위터의 카프카 도입 사례

왜 카프카를 사용해야 하는지 또는 카프카를 도입하는 것이 맞는지 알아보기 위해 잘란도와 트위터가 카프카를 어떻게 도입했는지 알아보자

### 1.1.1 유럽 최대 온라인 패션몰 잘란도의 도전 사례

잘란도는 독일의 무신사 같은 회사로 온라인 패션몰로 유명하다. 잘란도는 2020년 실사용자 3100만명부터 해서 매년 연평균 24%의 성장을 하는 기업이었다. 점차 회사의 규모가 커지자 회사 내부적으로 데이터에 대한 온갖 요구사항이 불거지자 잘란도는 이를 해결하기 위한 대책을 강구했고 이벤트 드리븐 시스템 아키텍처 도입을 결정했다.

하지만 이벤트 드리븐 시스템 아키텍처를 어떻게 잘 활용해야 하는가에 대한 대책이 필요했다. 데이터 신뢰성, 데이터의 멱등성, 데이터 검증, 통신 방법 등 여러 고민들을 해결해야했다. 동기 방식의 한계점을 느끼고 비동기 방식으로 전환을 고려한 잘란도는 비동기 방식의 대표 스트리밍 플랫폼인 카프카를 선택했는데 그 이유는 높은 처리량, 순서 보장, 적어도 한 번 전송 방식, 강력한 파티셔닝, 자연스러운 백프레셔 핸들링, 로그 컴팩션 같은 훌륭한 기능들 때문이었다.

**잘란도가 매력을 느낀 각 카프카 기능의 장점**

- 빠른 데이터 수집이 가능한 높은 처리량
    - HTTP 기반으로 전달되는 이벤트일지라도 응답시간은 불과 한자릿수의 ms
- 순서 보장
    - 이벤트 처리 순서 보장
- 적어도 한 번 전송 방식
    - 멱등성 보장
- 자연스러운 백프레셔 핸들링
    - 카프카의 클라이언트는 풀 방식으로 동작
- 강력한 파티셔닝
    - 각 파티션들을 다른 파티션들과 관계없이 처리가 가능해 효과적인 수평 확장 가능
- 그 외 여러가지 기능
    - 로그 컴팩션 기능을 통해 스냅샷 역할 등 여러 기능이 존재

### 1.1.2 SNS 절대 강자 트위터의 카프카 활용 사례

트위터는 처음 카프카 0.7버전을 사용했었는데 많은 I/O 오퍼레이션에서의 문제 발생 및 내구성, 리플리케이션의 미구현 등으로 인한 불안정성으로 카프카를 포기하고 인하우스 메시지 시스템을 구축했었다. 하지만 점차 카프카가 개발됨에 따라 빠른 응답시간, 높은 처리량, 펍/섭 모델을 지원하는 시스템으로 수평 확장이 용이하며 고가용성을 갖춘 시스템으로 성장해 다시 카프카로의 전환을 검토했다. 전환 목적은 비용 절감과 커뮤니티, 두 가지 측면이 고려됐다

**비용 절감 효과**

- 카프카 도입 전 인하우스에서 사용하던 이벤트 버스와 성능 차이를 비교해봤는데 아래와 같은 성능 차이를 보임. 더불어 카프카는 이벤트 버스와 다르게 OS에 의존해 백그라운드로 fsync를 처리하고 제로 카피를 사용해 이벤트 버스만큼의 많은 리소스가 필요치 않았다. 결국 카프카 도입으로 60~70%의 리소스 절감 효과를 누리게 되었다.

![Untitled](https://github.com/mash-up-kr/S3A/blob/03311cbd50e42a8e814e22dfdeabadc60276b1af/14th_kafka/jaemin/image/image1.png?raw=true)

**강력한 커뮤니티**

- 이미 많은 기업에서 사용해 다양한 사용자들의 경험을 공유할 수 있었다.

**아래와 같은 고민을 하고 있으면 카프카 도입을 검토해보자**

- 동기/비동기 데이터 전송에 대한 고민이 있는가?
- 실시간 데이터 처리에 대한 고민이 있는가?
- 현재의 데이터 처리에 한계를 느끼는가?
- 새로운 데이터 파이프라인이 복잡하다고 느끼는가?
- 데이터 처리의 비용 절감을 고려하고 있는가?

## 1.2 국내외 카프카 이용 현황

2020년 기준 포춘 100대 기업 중 약 80% 이상이 카프카를 사용하고 있음. 2018년 당시 카카오는 매일 240TB의 데이터가 카프카로 유입되고 있다.

## 1.3 카프카의 주요 특징

**카프카의 매력적인 기능들**

- 높은 처리량과 낮은 지연시간
    
    
![Untitled](https://github.com/mash-up-kr/S3A/blob/03311cbd50e42a8e814e22dfdeabadc60276b1af/14th_kafka/jaemin/image/image2.png?raw=true)
    
    - RabbitMQ, 펄사, 카프카를 비교해봤을때 카프카가 가장 높은 처리량을 갖고 있고 응답속도는 RabbitMQ가 높았으나 처리량과 응답 속도를 같이 비교했을 때는 카프카가 단연 독보적이었다.
- 높은 확장성
    - 이미 만들때부터 링크드인의 데이터 파이프라인의 확장성이 떨어지는 문제를 해결하기 위해 카프카를 개발했기에 첫 설계부터 확장 가능하도록 설계되었다.
- 고가용성
    - 카프카 초기에는 데이터 처리 속도를 빠르게 하는것이 목표였는데 점차 고가용성 측면도 중요하게 생각해 리플리케이션 기능을 추가해 고가용성을 얻었다.
- 내구성
    - 프로듀서는 카프카로 메시지를 전송할 때 프로듀서의 acks라는 옵션을 조정해 메시지의 내구성을 강화할 수 있는데 이 옵션을 all로 설정하면 매우 강력한 메시지 내구성을 얻을 수 있다.
- 개발 편의성
    - 프로듀서와 컨슈머가 완벽히 분리되어 있고 서로 영향을 주지도 받지도 않아 개발자들이 분리되어 서로의 역할에 해당하는 부분만 구현할 수 있다.
    - 카프카 커넥트와 스키마 레지스트리를 제공해 많은 개발자가 데이터 활용보다는 데이터를 파싱하는데 많은 시간을 소모한 문제점을 보완했다. 카프카 커넥트는 다양한 소스와 싱크를 제공해 다른 3rd party와의 연동도 쉽다
- 운영 및 관리 편의성
    - 최신 버전이 릴리지되는 경우 무중단 버전 업그레이드 지원
    - 그라파나 대시보드와 같이 사용해 운영

## 1.4 카프카의 성장

- 리플리케이션 기능 추가(v0.8)
    - 내부 카프카 클러스터에서 브로커의 장애가 발생해도 리플리케이션 기능으로 데이터 유실 없이 안정적으로 사용이 가능하다
- 스키마 레지스트리 공개(v0.8.2)
    - 펍/섭 모델에서 데이터 흐름이 대부분 브로드캐스트 방식이라 컨슈머가 프로듀서를 일방적으로 신뢰할 수 밖에 없는 구조였으나 스키마를 미리 등록 지정해 받고 싶은 데이터만 받을 수 있는 스키마 레지스트리 공개
- 카프카 커넥트 공개 (v0.9)
    - 기업들이 카프카를 많이 활용하면서 카프카와 연결해야하는 시스템들이 다양해졌다. DB만 해도 MySQL, SQL, PostreSQL 등 다양하기에 이런 문제를 해결하기 위해 카프카 커넥트를 공개해 별도의 코드 작성 없이 다양한 프로토콜과 카프카를 연동할 수 있게 되었다.
- 카프카 스트림즈 공개
    - 높은 처리량, 빠른 응답 속도를 바탕으로 실시간 처리에 대한 니즈를 해결하기 위해 카프카 스트림즈 공개
- KSQL 공개
    - SQL 기반으로 스트림 처리뿐 아니라 배치 처리를 가능하게 함
- 주키퍼 의존성에서 해방(v3.0)
    - 3.0 버전 이전에는 주키퍼가 필수적으로 사용되었으나 3.0버전 출시 후 주키퍼 없이 실행할 수 있는 카프카가 출시되었다.

## 1.5 다양한 카프카의 사용 사례

1. 데이터 파이프라인: 넷플릭스
    - 전 세계에 걸쳐 커다란 규모로 데이터를 수집, 통계, 처리, 적재하기 위한 파이프라인을 연결해주는 역할
2. 데이터 통합: 우버
    - 카프카를 중심으로 여러 데이터 파이프라인의 데이터들을 통합
3. 머신러닝 분야 활용
    - 모델 생성과 출력을 카프카 스트림즈를 사용해, 다양한 클라이언트와는 카프카 커넥트를 통해 설계가능
4. 스마트 시티 분야 활용
    - 다양한 지역에서 매일 발생하는 데이터를 수집하는데 사용

# 2장 카프카 환경 구성

## 카프카의 기본 구성

카프카는 데이터를 받아서 전달하는 데이터 버스의 역할을 한다. 카프카에 데이터를 만들어서 주는 쪽을 프로듀서, 데이터를 빼내서 소비하는 쪽을 컨슈머라 한다. 카프카의 정상 동작을 보장하기 위한 메타데이터를 관리하는 코디네이터인 주키퍼와 같이 사용된다.

주키퍼와의 의존성을 v3에서 없애서 추후에는 주키퍼를 따로 띄우지 않아도 될 듯 하다.

## 메시지 보내고 받기

메시지를 주고 받기 위해서는 메시지를 주고 받을 통로가 되는 토픽을 생성 후 컨슈머가 해당 토픽을 listen 한 후 프로듀서에서 메시지를 전송하면 된다.

### 토픽 생성

```docker
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server {ServerHost}:{port} \
--create --topic {TopicName} --partitions {partitionNumber} \
--replication-factor {CountOfReplications}
```

### 컨슈머 실행

```docker
~kafka-console-consumer.sh --bootstrap-server {ServerHost}:{port} \
--topic {topicName}
```

### 프로듀서 실행 및 메시지 전송

```docker
~kafka-console-producer.sh --bootstrap-server {ServerHost}:{port} \
--topic {topicName}
> {보낼 메시지}
```